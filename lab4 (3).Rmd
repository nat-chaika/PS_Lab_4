---
title: "Lab4"
author: "Vinnik Tetiana, Chaika Nataliia, Shevtsova Veronika"
output:
  html_document:
    df_print: paged
  html_notebook: default
  pdf_document: default
---

```{r}
require(BSDA)
library(BSDA)
require(EnvStats)   
library(EnvStats)
require(CPAT)
library(CPAT)
```

```{r}
n <- 0+2+2
set.seed(n)
```

```{r}
#function to get a_k={kln(k2n + π)}
f <- function(k, n) {
  n <- 4
  return(k*log(k^2*n+pi) - floor(k*log(k^2*n+pi))) 
}
```

```{r}
#generating data
k <- seq(1, 100)
l <- seq(101, 150)
a_k <- lapply(k, f)
a_l <- lapply(l, f)

x_k <- as.integer(lapply(a_k, qnorm))
y_l <- as.integer(lapply(a_l, qnorm))

```

#### Problem 1

$H0 : μ_1 = μ_2; \ H1 : μ_1 \ne μ_2$

Here we can use two sided z-test: we have 2 normal distributions and known variance

Rejection region:

Can use the generalized LRT with test statistics $2 log L_{x;y}(H_0;H_1)$

$$
2 log L_{x;y}(H_0;H_1) = \dfrac{mn}{m+n}\dfrac{(\bar{x}-\bar{y})^2}{\sigma^2} \geq x_{1-\alpha} \\
Z=Z(X, Y)=\sqrt{\dfrac{mn}{m+n}}\dfrac{\bar{x}-\bar{y}}{\sigma} \\
under H_0, Z\sim N(0, 1) \\
C_\alpha = \{xєR^n, yєR^m||z(x, y)|\geq z_{1-\alpha/2}\}
$$

```{r}
#for significance level 0.05
alpha <- 0.05
# |z(x,y)|
z_x_y <- abs(sqrt((100*50)/(100+50))*(mean(x_k)-mean(y_l))/1)
# quantile of standard normal distribution
z <- qnorm(1-alpha/2)
cat("|z(x, y)| = ", z_x_y, "\n")
cat("quantile =", z)
```

$|z(x, y)|< z_{1-\alpha/2} \text{ so } H_o \text{ should not be rejected on this significance level}$

```{r}
z.test(x_k, y_l, alternative = "two.sided", sigma.x=1, sigma.y=1)
```

p is big - probability to have first type error is big if we reject H0, so we should accept it

#### Problem 2

We use f-test because we have 2 samples and want to test their variances when means are unknown

Rejection region:

$$
S_{XX}/(n-1) - \ estimate\ for\ \sigma^2_1\\
S_{YY}/(m-1) - \ estimate\ for\ \sigma^2_2\\
Under\ H_0:\\
F(X, Y) = \dfrac{S_{XX}/(n-1)}{S_{YY}/(m-1)}\\
C_{\alpha}=\{xєR^n, yєR^m|f(x, y)\geq f_{\alpha}\},\\
f_\alpha - quantile\ for\ Fisher\ distribution
$$

```{r}
#f(x, y)
f_x_y <- (((sum((x_k-mean(x_k))^2))/99)/((sum((y_l-mean(y_l))^2))/49))
# f quantile
f <- qf(alpha, 99, 49)
cat("f(x, y) = ", f_x_y, "\n")
cat("quantile = ", f)
```

$f(x, y) \geq f_{\alpha}$

So on the significance level 0.05 H0 should be rejected

```{r}
var.test(x_k, y_l, alternative = "g")
```

p-value is small so we reject H0

#### Problem 3

For A, B:

General form of the rejection region:

$$
Under \ H_0 \ the\ statistics\\ d := \sup\limits_{t∈{\rm I\!R}} |\hat{F_x}(t) − F_0(t)|\\ C_\alpha := \{\boldsymbol{_X}∈{\rm I\!R}^n|d\ge d^{(n)}_{1-\alpha} \}\\
d^{(n)}_{1-\alpha} \text{- quantile of the Kolmogorov distribution}
$$

##### A)

H0 - data is drawn from a normal distribution. H1 - not from a normal one.

```{r}
#A.
#visualisation
x_u <- unique(x_k)
xlims <- c(mean(x_u)-3*sd(x_u),mean(x_u)+3*sd(x_u))
Fs <- ecdf(x_u)
plot(Fs, 
     xlim = xlims, 
     col = "blue",
     lwd = 2)
x <- seq(min(x_u), max(x_u), by = 0.1)
curve(pnorm(x, mean = mean(x_u), sd = sd(x_u)), col = "red", lwd = 2, add = TRUE)

#statistics d
d <- max(abs(ecdf(x_u)(x)-pnorm(x, mean = mean(x_u), sd = sd(x_u))))

#quantile of the Kolmogorov distribution
d_a <- CPAT:::qkolmogorov(1-alpha, 100)

cat("d = ", d, "\n")
cat("quantile = ", d_a)
```

$d< d^{(n)}_{1-\alpha}$So on the significance level 0.05 $H_0$ should be accepted

```{r}
ks.test(x_u, "pnorm", mean=mean(x_u), sd=sd(x_u))
```

Since P-value is close to 1, there is high chance that we will get First type error, so we accept $H_0$ hypothesis.

##### B)

H0 - data is drawn from an exponencial distribution. H1 - not from an exponencial one.

```{r}
#B.
x_abs <- abs(x_k)
x_abs <- unique(x_abs)

#visualization
xlims <- c(mean(x_abs)-3*sd(x_abs),mean(x_abs)+3*sd(x_abs))
Fs <- ecdf(x_abs)
plot(Fs, 
     xlim = xlims, 
     col = "blue",
     lwd = 2)
x <- seq(min(x_abs), max(x_abs), by = 0.1)
curve(pexp(x, rate = 1), col = "red", lwd = 2, add = TRUE)

#statistic d
d <- max(abs(ecdf(x_abs)(x)-pexp(x, rate=1)))

# quantile of the Kolmogorov distribution with n=4, alpha = 0.05
d_a <- 0.565

cat("d = ", d, "\n")
cat("quantile = ", d_a)
```

$d< d^{(n)}_{1-\alpha}$So on the significance level 0.05 $H_0$ should be accepted

```{r}
ks.test(x_abs, "pexp", rate=1)
```

Since P-value is high enough, there is big chance that we will get First type error, so we accept $H_0$ hypothesis.

##### C)

H0 \-- x_k and y_l are drawn from the same distribution. H1 \-- not from the same one.

For C: General form of the rejection region: $$
Under \ H_0 \ the\ statistics\\ d := \sup\limits_{t∈{\rm I\!R}} |\hat{F_X}(t) − \hat{F_Y}(t)|\\ C\alpha := \{{\boldsymbol{_X}∈{\rm I\!R}^n, \boldsymbol{_Y}∈{\rm I\!R}^n|d\ge d^{(n)}_{1-\alpha} }\}
$$

```{r}
#C.
x <- seq(min(x_k, y_l), max(x_k, y_l), by = 0.01)

#statistic d
d <- max(abs(ecdf(x_k)(x)-ecdf(y_l)(x)))

#quantile of the Kolmogorov distribution
d_a <- CPAT:::qkolmogorov(1-alpha, 100)

cat("d = ", d, "\n")
cat("quantile = ", d_a)
```

So on the significance level 0.05 $H_0$ should be accepted.

```{r}
ks.test(x_k, y_l)
```

The P-value is bigger than rejection level. That's why we accept $H_0$ to avoid First type error.
